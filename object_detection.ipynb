{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaVVoL1ScD6Y1bJ6jRAtHR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phionanamugga/Autonomous_Navigation/blob/main/object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s9w5ieV37CFB"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "import time\n",
        "import supervision as sv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')  # Pre-trained YOLOv8 nano model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wPMNJeL_jii",
        "outputId": "d6ee609a-5062-40f4-8d01-4c6738cbbf87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100%|██████████| 6.25M/6.25M [00:00<00:00, 49.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DeepSORT tracker\n",
        "tracker = DeepSort(max_age=30, nn_budget=100, nms_max_overlap=1.0)"
      ],
      "metadata": {
        "id": "gn1lRTUl_5Me"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize video capture (replace with your video file or camera)\n",
        "cap = cv2.VideoCapture('sample_traffic_video.mp4')"
      ],
      "metadata": {
        "id": "govAmp1yAIou"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize supervision annotators\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n"
      ],
      "metadata": {
        "id": "2V8mtzM7Agwl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model(frame)[0]\n",
        "    detections = []\n",
        "    for box in results.boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "        conf = float(box.conf)\n",
        "        cls = int(box.cls)\n",
        "        if conf > 0.5:  # Confidence threshold\n",
        "            detections.append(([x1, y1, x2 - x1, y2 - y1], conf, cls))\n",
        "\n",
        "    # Update tracker with detections\n",
        "    tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "    # Prepare detections for supervision\n",
        "    bboxes = []\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    track_ids = []\n",
        "\n",
        "    for track in tracks:\n",
        "        if not track.is_confirmed():\n",
        "            continue\n",
        "        ltrb = track.to_ltrb()\n",
        "        bboxes.append(ltrb)\n",
        "        class_ids.append(track.det_class)\n",
        "        confidences.append(track.det_conf)\n",
        "        track_ids.append(track.track_id)\n",
        "\n",
        "    # Convert to supervision Detections\n",
        "    detections = sv.Detections(\n",
        "        xyxy=np.array(bboxes),\n",
        "        class_id=np.array(class_ids),\n",
        "        confidence=np.array(confidences),\n",
        "        tracker_id=np.array(track_ids)\n",
        "    )\n",
        "\n",
        "    # Annotate frame\n",
        "    annotated_frame = box_annotator.annotate(scene=frame.copy(), detections=detections)\n",
        "    labels = [f\"ID {track_id} {model.names[class_id]}\" for track_id, class_id in zip(detections.tracker_id, detections.class_id)]\n",
        "    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
        "\n",
        "    # Display frame\n",
        "    cv2.imshow('Object Detection and Tracking', annotated_frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n"
      ],
      "metadata": {
        "id": "xxYsnsGJBL1a"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}